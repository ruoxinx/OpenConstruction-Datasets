<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenConstruction — Updates</title>
    <link>http://ruoxinx.github.io/open-construction-test/</link>
    <description>Newest datasets and models from OpenConstruction</description>
    <language>en-US</language>

  <item>
    <title><![CDATA[Dataset: Architectural–structural Design Pairs]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/datasets/detail.html?id=structgan</link>
    <guid isPermaLink="false">datasets:structgan:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: ETHcavation: A Dataset and Pipeline for Panoptic Scene Understanding and Object Tracking in Dynamic Construction Environments]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=ETHcavation</link>
    <guid isPermaLink="false">models:ETHcavation:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Construction sites are challenging environments for autonomous systems due to their unstructured nature and the presence of dynamic actors, such as workers and machinery. This work presents a comprehensive panoptic scene understanding solution designed to handle the complexities of such environments by integrating 2D panoptic segmentation with 3D LiDAR mapping. Our system generates detailed environmental representations in real-time by combining semantic and geometric data, supported by Kalman Filter-based tracking for dynamic object detection. We introduce a fine-tuning method that adapts large pre-trained panoptic segmentation models for construction site applications using a limited number of domain-specific samples. For this use case, we release a first-of-its-kind dataset of 502 hand-labeled sample images with panoptic annotations from construction sites. In addition, we propose a dynamic panoptic mapping technique that enhances scene understanding in unstructured environments. As a case study, we demonstrate the system's application for autonomous navigation, utilizing real-time RRT* for reactive path planning in dynamic scenarios. The dataset and code for training and deployment are publicly available to support future research.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Buildee: A 3D Simulation Framework for Scene Exploration and Reconstruction with Understanding]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=Buildee</link>
    <guid isPermaLink="false">models:Buildee:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[We introduce Buildee, a 3D simulation framework designed to benchmark scene exploration, 3D reconstruction, and semantic segmentation tasks in both static and dynamic environments. Built as a Python module on top of Blender, Buildee leverages its advanced rendering capabilities to generate realistic RGB, depth, and semantic data while enabling 2D / 3D point tracking and occlusion checking. Additionally, we provide a procedural generator for construction site environments and baseline methods for key computer vision tasks. Through Buildee, we establish a standardized platform for evaluating scene understanding algorithms in realistic settings. Our code is publicly available at https://github.com/clementinboittiaux/buildee.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Advancing construction site workforce safety monitoring through BIM and computer vision integration]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=Worker-Safety-Twin</link>
    <guid isPermaLink="false">models:Worker-Safety-Twin:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Ensuring a safe work environment is crucial for construction projects. It is essential that workforce monitoring is both efficient and non-intrusive to the ongoing construction activities. This paper introduces a method that integrates building information modeling (BIM) and computer vision to monitor workforce safety hazards at construction sites in real time. Despite the rising adoption of BIM and computer vision individually within the construction sector, the potential of their integrated application as a cohesive system for workforce safety monitoring remains unexplored. While BIM provides rich 3D semantic information about the construction site, computer vision captures real-time field data. The system was tested using a realistic construction simulation, and the accuracy of the position estimate was evaluated in a real-world interior environment, yielding a mean error distance (MED) of 13.2 cm. Overall, the findings have substantial significance for the construction industry to help minimize accidents and enhance overall worker safety.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Automated Structural Design of Shear Wall Residential Buildings using Generative Adversarial Networks (StructGAN)]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=structgan-v1</link>
    <guid isPermaLink="false">models:structgan-v1:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Artificial intelligence is reshaping building design processes to be smarter and automated. Considering the increasingly wide application of shear wall systems in high-rise buildings and envisioning the massive benefit of automated structural design, this paper proposes a generative adversarial network (GAN)-based shear wall design method, which learns from existing shear wall design documents and then performs structural design intelligently and swiftly. To this end, structural design datasets were prepared via abstraction, semanticization, classification, and parameterization in terms of building height and seismic design category. The GAN model improved its shear wall design proficiency through adversarial training supported by data and hyper-parametric analytics. The performance of the trained GAN model was appraised against the metrics based on the confusion matrix and the intersection-over-union approach. Finally, case studies were conducted to evaluate the applicability, effectiveness, and appropriateness of the innovative GAN-based structural design method, indicating significant speed-up and comparable quality.Artificial intelligence is reshaping building design processes to be smarter and automated. Considering the increasingly wide application of shear wall systems in high-rise buildings and envisioning the massive benefit of automated structural design, this paper proposes a generative adversarial network (GAN)-based shear wall design method, which learns from existing shear wall design documents and then performs structural design intelligently and swiftly. To this end, structural design datasets were prepared via abstraction, semanticization, classification, and parameterization in terms of building height and seismic design category. The GAN model improved its shear wall design proficiency through adversarial training supported by data and hyper-parametric analytics. The performance of the trained GAN model was appraised against the metrics based on the confusion matrix and the intersection-over-union approach. Finally, case studies were conducted to evaluate the applicability, effectiveness, and appropriateness of the innovative GAN-based structural design method, indicating significant speed-up and comparable quality.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: UGD: Underground Garage Point Cloud Dataset]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/datasets/detail.html?id=UGD</link>
    <guid isPermaLink="false">datasets:UGD:2025-09-27</guid>
    <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: SORD Dataset: Synthetic On-site Rebar Data]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/datasets/detail.html?id=SORD</link>
    <guid isPermaLink="false">datasets:SORD:2025-09-27</guid>
    <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Tower crane hook dataset]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/datasets/detail.html?id=hook</link>
    <guid isPermaLink="false">datasets:hook:2025-09-27</guid>
    <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Automatic repetitive action counting for construction worker ergonomic assessment]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=repetitive-action</link>
    <guid isPermaLink="false">models:repetitive-action:2025-09-27</guid>
    <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Work-related musculoskeletal disorders are the primary cause of nonfatal occupational injuries in the construction industry. Accurate ergonomic assessment is essential to reduce the risk of work-related injuries. Repetitive work significantly contributes to musculoskeletal injuries, and various ergonomic evaluation methods have specific criteria for assessing repetitive actions. However, most existing methods for repetitive motions primarily rely on subjective and time-consuming manual observation. To accurately assess ergonomic risk, an automatic and precise method is required to count repetitive actions in construction work. This poses a challenge due to the unstructured nature of construction actions and their varying frequencies and cycles. This paper aims to overcome these challenges by identifying repetitive unstructured actions using posture self-similarity comparison and predicting construction actions' length using a transformer layer. Experimental results demonstrated that the proposed method achieved a 91.5 % accuracy in identifying repetitive actions. The research results will contribute to the promotion of accurate ergonomics evaluation of automation.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: Deep Learning for Site Safety: Real-Time Detection of Personal Protective Equipment]]></title>
    <link>http://ruoxinx.github.io/open-construction-test/models/detail.html?id=Pictor-v3</link>
    <guid isPermaLink="false">models:Pictor-v3:2025-09-27</guid>
    <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[The leading causes of construction fatalities include traumatic brain injuries (resulted from fall and electrocution) and collisions (resulted from struck by objects). As a preventive step, the U.S. Occupational Safety and Health Administration (OSHA) requires that contractors enforce and monitor appropriate usage of personal protective equipment (PPE) of workers (e.g., hard hat and vest) at all times. This paper presents three deep learning (DL) models built on You-Only-Look-Once (YOLO) architecture to verify PPE compliance of workers; i.e., if a worker is wearing hard hat, vest, or both, from image/video in real-time. In the first approach, the algorithm detects workers, hats, and vests and then, a machine learning model (e.g., neural network and decision tree) verifies if each detected worker is properly wearing hat or vest. In the second approach, the algorithm simultaneously detects individual workers and verifies PPE compliance with a single convolutional neural network (CNN) framework. In the third approach, the algorithm first detects only the workers in the input image which are then cropped and classified by CNN-based classifiers (i.e., VGG-16, ResNet-50, and Xception) according to the presence of PPE attire. All models are trained on an in-house image dataset that is created using crowd-sourcing and web-mining. The dataset, named Pictor-v3, contains ~1,500 annotated images and ~4,700 instances of workers wearing various combinations of PPE components. It is found that the second approach achieves the best performance, i.e., 72.3% mean average precision (mAP), in real-world settings, and can process 11 frames per second (FPS) on a laptop computer which makes it suitable for real-time detection, as well as a good candidate for running on light-weight mobile devices. The closest alternative in terms of performance (67.93% mAP) is the third approach where VGG-16, ResNet-50, and Xception classifiers are assembled in a Bayesian framework. However, the first approach is the fastest among all and can process 13 FPS with 63.1% mAP. The crowed-sourced Pictor-v3 dataset and all trained models are publicly available to support the design and testing of other innovative applications for monitoring safety compliance, and advancing future research in automation in construction.]]></description>
  </item>
  </channel>
</rss>
