<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenConstruction — Updates</title>
    <link>https://github.com/ruoxinx/open-construction/</link>
    <description>Newest datasets and models from OpenConstruction</description>
    <language>en-US</language>

  <item>
    <title><![CDATA[Model: Vitruvio: Conditional variational autoencoder to generate building meshes via single perspective sketches]]></title>
    <link>https://github.com/ruoxinx/open-construction/models/detail.html?id=Vitruvio</link>
    <guid isPermaLink="false">models:Vitruvio:2025-09-30</guid>
    <pubDate>Tue, 30 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[At the beginning of a project, architects convey design ideas via quick 2D diagrams, front views, floor plans, and sketches. Consequently, many stakeholders have difficulty visualizing the 3D representation of the building mass, leading to varied interpretations thus inhibiting a shared understanding of the design. To alleviate the challenge, this paper proposes a deep learning-based method, Vitruvio, for creating a 3D model from a single perspective sketch. This method allows designers to automatically generate 3D representations in real-time based on their initial sketches and thus communicate effectively and intuitively to the client. Vitruvio adapts the Occupancy Network to perform single view reconstruction (SVR), a technique for creating 3D representations from a single image. Vitruvio achieves: (1) an 18% increase in the reconstruction accuracy and (2) a 26% reduction in the inference time compared to the Occupancy Network on one thousand buildings provided by the New York municipality. This research investigates the effect that the building orientation has on the reconstruction quality, discovering that Vitruvio can capture fine-grain details in complex buildings when their native orientation is preserved during training, as opposed to the SVR's standard practice that aligns every building to its canonical pose. The code is available here https://github.com/CDInstitute/Vitruvio.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: OccFaçade: Enabling precise building façade parsing in large urban scenes with occlusion]]></title>
    <link>https://github.com/ruoxinx/open-construction/models/detail.html?id=OccFa%C3%A7ade</link>
    <guid isPermaLink="false">models:OccFaçade:2025-09-29</guid>
    <pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Building façade parsing is to recognize the building façade image into different categories of individuals including walls, doors, windows, balconies, etc. However, obstructions such as trees present a significant challenge to conducting façade parsing. In this paper, we designed OccFaçade to achieve high-precision parsing of occluded building façades in large urban scenes. OccFaçade primarily incorporates two modules, Multi-layer Dilated Convolution Module (MD-Module) and Multi-scale Row-Column Convolution Module (MRC-Module), to capture repeated texture in local and row-column directions. This aims to leverage repetitive textures to address occlusion challenges in building façade parsing. Besides, we introduce our building façade dataset MeshFaçade from the Mesh data generated by drone imagery to study the occlusion problem of missing textures. The experimental results demonstrate that OccFaçade achieves state-of-the-art performance with mIOU of 85.01%, 84.09%, 72.95%, and 88.83% on the ENPC2014 dataset, ECP dataset, RueMonge2014 dataset, and our MeshFaçade dataset, respectively. The code and data are available at https://github.com/yueyisui/OccFacade.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: A synthetic data-enhanced method for automated 3D pose recognition of construction workers]]></title>
    <link>https://github.com/ruoxinx/open-construction/models/detail.html?id=MultiWorker3DPose</link>
    <guid isPermaLink="false">models:MultiWorker3DPose:2025-09-29</guid>
    <pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Automated 3D pose recognition of construction workers is instrumental to analyzing their occupational safety and health, productivity and other jobsite behaviors. Existing studies in this field have been confined to high-quality training datasets collected from real-life construction jobsites, potentially triggering ethical, privacy, and cost concerns. Inspired by the success of synthetic data in other fields, this research proposes a synthetic data-enhanced method for automated 3D pose recognition of construction workers. It generates a synthetic dataset to supplement a real-life dataset for model training, presents a monocular vision-based model for recognizing multiple workers’ 3D poses, and then validates the model performance. Experiments verify that this model jointly trained with synthetic and real data outperforms a model trained on real data alone. The data enrichment approach explored in this study offers reliable data quality at less expense than real data-focused approaches. This research therefore lays a foundation for a series of studies to enhance workers’ occupational safety and health and productivity.]]></description>
  </item>

  <item>
    <title><![CDATA[Model:  Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry]]></title>
    <link>https://github.com/ruoxinx/open-construction/models/detail.html?id=SkeySpot</link>
    <guid isPermaLink="false">models:SkeySpot:2025-09-29</guid>
    <pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Legacy floor plans, often preserved only as scanned documents, remain essential resources for architecture, urban planning, and facility management in the construction industry. However, the lack of machine-readable floor plans render large-scale interpretation both time-consuming and error-prone. Automated symbol spotting offers a scalable solution by enabling the identification of service key symbols directly from floor plans, supporting workflows such as cost estimation, infrastructure maintenance, and regulatory compliance. This work introduces a labelled Digitised Electrical Layout Plans (DELP) dataset comprising 45 scanned electrical layout plans annotated with 2,450 instances across 34 distinct service key classes. A systematic evaluation framework is proposed using pretrained object detection models for DELP dataset. Among the models benchmarked, YOLOv8 achieves the highest performance with a mean Average Precision (mAP) of 82.5%. Using YOLOv8, we develop SkeySpot, a lightweight, open-source toolkit for real-time detection, classification, and quantification of electrical symbols. SkeySpot produces structured, standardised outputs that can be scaled up for interoperable building information workflows, ultimately enabling compatibility across downstream applications and regulatory platforms. By lowering dependency on proprietary CAD systems and reducing manual annotation effort, this approach makes the digitisation of electrical layouts more accessible to small and medium-sized enterprises (SMEs) in the construction industry, while supporting broader goals of standardisation, interoperability, and sustainability in the built environment.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: Architectural–structural Design Pairs]]></title>
    <link>https://github.com/ruoxinx/open-construction/datasets/detail.html?id=structgan</link>
    <guid isPermaLink="false">datasets:structgan:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: MEP2BIM Dataset]]></title>
    <link>https://github.com/ruoxinx/open-construction/datasets/detail.html?id=mep2bim</link>
    <guid isPermaLink="false">datasets:mep2bim:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: BFA-YOLO Construction Safety Dataset]]></title>
    <link>https://github.com/ruoxinx/open-construction/datasets/detail.html?id=bfa-yolo-dataset</link>
    <guid isPermaLink="false">datasets:bfa-yolo-dataset:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: MLSTRUCT-FP: Machine Learning STRUCTural Floor Plan Dataset]]></title>
    <link>https://github.com/ruoxinx/open-construction/datasets/detail.html?id=mlstruct-fp</link>
    <guid isPermaLink="false">datasets:mlstruct-fp:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Dataset: TBBR dataset: Thermal Bridges on Building Rooftops]]></title>
    <link>https://github.com/ruoxinx/open-construction/datasets/detail.html?id=TBBR</link>
    <guid isPermaLink="false">datasets:TBBR:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[New dataset added to OpenConstruction.]]></description>
  </item>

  <item>
    <title><![CDATA[Model: ETHcavation: A Dataset and Pipeline for Panoptic Scene Understanding and Object Tracking in Dynamic Construction Environments]]></title>
    <link>https://github.com/ruoxinx/open-construction/models/detail.html?id=ETHcavation</link>
    <guid isPermaLink="false">models:ETHcavation:2025-09-28</guid>
    <pubDate>Sun, 28 Sep 2025 00:00:00 GMT</pubDate>
    <description><![CDATA[Construction sites are challenging environments for autonomous systems due to their unstructured nature and the presence of dynamic actors, such as workers and machinery. This work presents a comprehensive panoptic scene understanding solution designed to handle the complexities of such environments by integrating 2D panoptic segmentation with 3D LiDAR mapping. Our system generates detailed environmental representations in real-time by combining semantic and geometric data, supported by Kalman Filter-based tracking for dynamic object detection. We introduce a fine-tuning method that adapts large pre-trained panoptic segmentation models for construction site applications using a limited number of domain-specific samples. For this use case, we release a first-of-its-kind dataset of 502 hand-labeled sample images with panoptic annotations from construction sites. In addition, we propose a dynamic panoptic mapping technique that enhances scene understanding in unstructured environments. As a case study, we demonstrate the system's application for autonomous navigation, utilizing real-time RRT* for reactive path planning in dynamic scenarios. The dataset and code for training and deployment are publicly available to support future research.]]></description>
  </item>
  </channel>
</rss>
